{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3b9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "# from bytelatent.transformer import LMTransformer, LMTransformerArgs\n",
    "from bytelatent.entropy_model_core import GPTConfig, GPT\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "def load_entropy_model(\n",
    "        entropy_model_checkpoint_dir=\"/home/AD/sachith/CAPE-TST/timeblt2/bytelatent/data/pretrained_entropy_model/\", \n",
    "        state_dict_path=\"/home/AD/sachith/CAPE-TST/timeblt2/bytelatent/data/pretrained_entropy_model/entropy_model.pt\", \n",
    "        device=\"cpu\"\n",
    "        ):\n",
    "    \n",
    "    with open(os.path.join(entropy_model_checkpoint_dir, \"params.json\")) as fr:\n",
    "        reloaded = json.loads(fr.read())\n",
    "\n",
    "    torch.set_default_dtype(torch.bfloat16)\n",
    "    model_params = reloaded[\"entropy_model\"]\n",
    "    logger.warning(\n",
    "        \"Update checkpoint to load attn and sliding window args from checkpoint\"\n",
    "    )\n",
    "\n",
    "    entropy_model_args = GPTConfig(\n",
    "        n_layer=model_params[\"n_layer\"],\n",
    "        n_head=model_params[\"n_head\"],\n",
    "        n_embd=model_params[\"n_embd\"],\n",
    "        dropout=model_params[\"dropout\"],\n",
    "        bias=model_params[\"bias\"],\n",
    "        vocab_size=model_params[\"vocab_size\"],\n",
    "        block_size=model_params[\"block_size\"]\n",
    "    )\n",
    "    entropy_model = GPT(entropy_model_args)\n",
    "    print(entropy_model)\n",
    "\n",
    "    entropy_model.load_state_dict(torch.load(state_dict_path, map_location=device, weights_only=True)[\"model_state_dict\"], strict=False)\n",
    "    \n",
    "    entropy_model.to(device)\n",
    "    entropy_model = entropy_model.eval()\n",
    "    # no grads for the model:\n",
    "    for param in entropy_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return entropy_model, entropy_model_args"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
